# Update baseball.computer Data Through 2025

**Date:** 2025-01-31
**Author:** Design session with Claude
**Status:** Draft

## Problem

The baseball.computer database hasn't been updated with recent seasons. The site currently serves stale data.

## Goal

Add data for the 2023, 2024, and 2025 MLB seasons. Start with recent years (last 3) with extensibility to add more historical data later.

## Architecture

The baseball.computer project has a two-part architecture:

1. **Rust Parser** (`baseball.computer.rs`): Converts Retrosheet's raw event files (.EVN/.EVA) into DuckDB tables
2. **dbt Pipeline** (this repo): Transforms those tables into the final analytical database

```
Retrosheet .ZIP files (2023, 2024, 2025)
    ↓
Rust Parser (baseball.computer.rs)
    ↓
DuckDB staging tables (*.duckdb files)
    ↓
dbt run (this repo)
    ↓
Aggregated metrics & advanced stats
    ↓
scripts/create_web_db.py
    ↓
Parquet files uploaded to Cloudflare R2
```

## Implementation Steps

### 1. Clone and Set Up Rust Parser

```bash
cd ..  # Parent directory of baseball.computer
git clone https://github.com/droher/baseball.computer.rs
cd baseball.computer.rs
cargo build --release
```

### 2. Download Retrosheet Data

Download event ZIP files from `https://www.retrosheet.org/game.htm`:
- `2025eve.zip`
- `2024eve.zip`
- `2023eve.zip`

Each ZIP contains:
- **.EVN/.EVA files**: Play-by-play event data
- **.ROS files**: Team rosters
- **TEAM files**: Team information

### 3. Run Rust Parser

Execute the parser to generate DuckDB staging tables:

```bash
# From baseball.computer.rs
./target/release/baseball-computer-rs --input ../retrosheet --output ../baseball.computer/data
```

Expected output tables (matching `bc/models/staging/event/source.yml`):
- `events`
- `event_baserunners`
- `event_comments`
- `event_fielding_play`
- `event_flags`
- `event_pitch_sequences`
- `event_audit`

### 4. Run dbt Pipeline

```bash
cd ../baseball.computer/bc
dbt run
```

This builds all transformation layers:
- **Staging** → Raw data normalization
- **Intermediate** → Event states, park factors, run expectancy, win expectancy, fielding plays
- **Metrics** → Player career/season stats, team season aggregates, standings

### 5. Deploy to Cloudflare R2

```bash
cd ..
python scripts/create_web_db.py
```

This exports each dbt model to Parquet and uploads to `data.baseball.computer/dbt/`.

### 6. Verification

Query the deployed database to confirm:
1. 2025 games exist
2. Player counts match expected
3. Website Query Engine returns 2025 results

## Extensibility

To add more years:
1. Download additional Retrosheet ZIPs
2. Re-run parser with new data
3. Re-run `dbt run`
4. Re-deploy

## Notes

- Retrosheet has event-level data back to 1921 (with some earlier sporadic coverage)
- The dbt pipeline is already tested and working (recent bug fixes confirmed this)
- No code changes should be needed, only data ingestion
